# ML Service для анализа отзывов

FastAPI сервис для классификации тем и определения тональности отзывов.

## Особенности

- **Мультилейбл классификация**: один отзыв может относиться к нескольким темам
- **Анализ тональности**: для каждой темы определяется тональность (положительно/нейтрально/отрицательно)
- **Быстрая работа**: использует легковесную модель rubert-tiny
- **Rule-based подход**: определение тем на основе ключевых слов
- **Контекстный анализ**: тональность определяется для контекста вокруг каждой темы

## Темы

1. Карты
2. Кэшбек и бонусы
3. Мобильное приложение
4. Служба поддержки
5. Отделения
6. Депозиты и вклады
7. Переводы и платежи
8. Кредиты и ипотека
9. Премиум-обслуживание
10. Комиссии и тарифы
11. Безопасность
12. Дистанционное обслуживание
13. Обслуживание и сервис

## Локальный запуск

```bash
# Установка зависимостей
pip install -r requirements.txt

# Запуск сервиса
uvicorn app:app --host 0.0.0.0 --port 8000 --reload
```

## Docker

```bash
# Сборка образа
docker build -t ml-service .

# Запуск контейнера
docker run -p 8000:8000 ml-service
```

## API Endpoints

### POST /predict

Основной эндпоинт для предсказания тем и тональностей.

**Запрос:**
```json
{
    "data": [
        {
            "id": 1,
            "text": "Очень понравилось обслуживание в отделении, но мобильное приложение часто зависает."
        }
    ]
}
```

**Ответ:**
```json
{
    "predictions": [
        {
            "id": 1,
            "topics": ["Отделения", "Мобильное приложение"],
            "sentiments": ["положительно", "отрицательно"]
        }
    ]
}
```

### GET /topics

Получить список всех доступных тем.

### GET /health

Проверка здоровья сервиса.

## Технические детали

- **Модель тональности**: `cointegrated/rubert-tiny-sentiment-balanced`
- **Макс. размер батча**: 250 отзывов
- **Время обработки**: до 3 минут для 250 отзывов
- **Поддержка GPU**: автоматическое определение и использование CUDA
